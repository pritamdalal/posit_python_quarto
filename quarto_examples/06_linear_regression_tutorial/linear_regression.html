<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Simple Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="linear_regression_files/libs/clipboard/clipboard.min.js"></script>
<script src="linear_regression_files/libs/quarto-html/quarto.js"></script>
<script src="linear_regression_files/libs/quarto-html/popper.min.js"></script>
<script src="linear_regression_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="linear_regression_files/libs/quarto-html/anchor.min.js"></script>
<link href="linear_regression_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="linear_regression_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="linear_regression_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="linear_regression_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="linear_regression_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#import-packages" id="toc-import-packages" class="nav-link active" data-scroll-target="#import-packages">Import Packages</a></li>
  <li><a href="#loading-data" id="toc-loading-data" class="nav-link" data-scroll-target="#loading-data">Loading Data</a></li>
  <li><a href="#exploratory-data-analysis-implied-volatility-as-a-fear-index-leverage-effect" id="toc-exploratory-data-analysis-implied-volatility-as-a-fear-index-leverage-effect" class="nav-link" data-scroll-target="#exploratory-data-analysis-implied-volatility-as-a-fear-index-leverage-effect">Exploratory Data Analysis: Implied Volatility as a Fear Index (Leverage Effect)</a></li>
  <li><a href="#regression-example-1-returns-vs-change-in-implied-volatility" id="toc-regression-example-1-returns-vs-change-in-implied-volatility" class="nav-link" data-scroll-target="#regression-example-1-returns-vs-change-in-implied-volatility">Regression Example 1: Returns vs Change in Implied Volatility</a></li>
  <li><a href="#regression-example-2-realized-volatility-clustering" id="toc-regression-example-2-realized-volatility-clustering" class="nav-link" data-scroll-target="#regression-example-2-realized-volatility-clustering">Regression Example 2: Realized Volatility Clustering</a></li>
  <li><a href="#forecasting-realized-volatility" id="toc-forecasting-realized-volatility" class="nav-link" data-scroll-target="#forecasting-realized-volatility">Forecasting Realized Volatility</a></li>
  <li><a href="#updating-our-forecasting-model-daily" id="toc-updating-our-forecasting-model-daily" class="nav-link" data-scroll-target="#updating-our-forecasting-model-daily">Updating our Forecasting Model Daily</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading">Further Reading</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Simple Linear Regression</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>This tutorial is an intuitive introduction to simple linear regression in a finance context. In particular, we will fit regressions that demonstrate two stylized facts about volatility in SPY:</p>
<ol type="1">
<li>The Leverage Effect: there is an inverse relationship between implied volatility and returns.</li>
<li>Volatility Clustering: current high/low realized volatility predicts future high/low realized volatility.</li>
</ol>
<p>Our focus will be on how to implement linear regression in Python, rather than on its mathematical/statistical details.</p>
<p>Linear Regression will serve as our first introduction to <code>sklearn</code>, a popular package for implementing various machine learning models in Python.</p>
<section id="import-packages" class="level3">
<h3 class="anchored" data-anchor-id="import-packages">Import Packages</h3>
<p>Let’s begin by loading the packages that we will need.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns<span class="op">;</span> sns.<span class="bu">set</span>()</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="loading-data" class="level3">
<h3 class="anchored" data-anchor-id="loading-data">Loading Data</h3>
<p>The dataset that we will analyze in this tutorial consists of weekly volatility metrics for SPY during 2014-2018. Each row of the <code>DataFrame</code> is a set of observations from a specific week. In particular:</p>
<ol type="1">
<li><code>realized_vol</code> - standard deviation of returns during period (annualized).</li>
<li><code>ret</code> - simple return for the period.</li>
<li><code>start_iv</code> - the implied vol (variance swap rate) at the start of the period.</li>
</ol>
<p>Let’s read-in the data set and have a look.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df_spy <span class="op">=</span> pd.read_csv(<span class="st">'spy_2014_2018_regression.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df_spy.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>underlying</th>
      <th>start_date</th>
      <th>end_date</th>
      <th>realized_vol</th>
      <th>ret</th>
      <th>start_iv</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SPY</td>
      <td>2014-01-03</td>
      <td>2014-01-10</td>
      <td>0.052949</td>
      <td>0.006812</td>
      <td>0.104300</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SPY</td>
      <td>2014-01-10</td>
      <td>2014-01-17</td>
      <td>0.147207</td>
      <td>-0.002719</td>
      <td>0.093948</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SPY</td>
      <td>2014-01-17</td>
      <td>2014-01-24</td>
      <td>0.176336</td>
      <td>-0.026206</td>
      <td>0.103134</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SPY</td>
      <td>2014-01-24</td>
      <td>2014-01-31</td>
      <td>0.136391</td>
      <td>-0.003977</td>
      <td>0.195719</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SPY</td>
      <td>2014-01-31</td>
      <td>2014-02-07</td>
      <td>0.235160</td>
      <td>0.008383</td>
      <td>0.182371</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="exploratory-data-analysis-implied-volatility-as-a-fear-index-leverage-effect" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis-implied-volatility-as-a-fear-index-leverage-effect">Exploratory Data Analysis: Implied Volatility as a Fear Index (Leverage Effect)</h3>
<p>Options are simple insurance contracts that are written on top of an underlying stock. They protect against large moves in the price of the underlying. Puts protect against downward moves, calls protect against upward moves.</p>
<p>The <em>implied volatility</em> of a stock is a measurement that gauges how much market participants are willing to pay for options on that stock. Thus, the implied volatility of a stock serves as a index of how fearful market participants are about large moves in the stock price.</p>
<p><strong>The Leverage Effect:</strong> For many stocks, especially index-ETFs, the following two relationships hold:</p>
<ol type="1">
<li><p>Implied volatility increases when the stock experiences losses (negative returns).</p></li>
<li><p>Implied volatility decreases when the stock experiences gains (positive returns).</p></li>
</ol>
<p>Let’s try to see this relationship in our SPY weekly data by means of a simple scatter plot.</p>
<p>First, let’s create a new column in <code>df_spy</code> - we’ll call it <code>iv_change</code> - to capture the week over week change of the implied volatility.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df_spy[<span class="st">'iv_change'</span>] <span class="op">=</span> (df_spy[<span class="st">'start_iv'</span>] <span class="op">-</span> df_spy[<span class="st">'start_iv'</span>].shift(<span class="dv">1</span>)).shift(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df_spy.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>underlying</th>
      <th>start_date</th>
      <th>end_date</th>
      <th>realized_vol</th>
      <th>ret</th>
      <th>start_iv</th>
      <th>iv_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SPY</td>
      <td>2014-01-03</td>
      <td>2014-01-10</td>
      <td>0.052949</td>
      <td>0.006812</td>
      <td>0.104300</td>
      <td>-0.010352</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SPY</td>
      <td>2014-01-10</td>
      <td>2014-01-17</td>
      <td>0.147207</td>
      <td>-0.002719</td>
      <td>0.093948</td>
      <td>0.009187</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SPY</td>
      <td>2014-01-17</td>
      <td>2014-01-24</td>
      <td>0.176336</td>
      <td>-0.026206</td>
      <td>0.103134</td>
      <td>0.092585</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SPY</td>
      <td>2014-01-24</td>
      <td>2014-01-31</td>
      <td>0.136391</td>
      <td>-0.003977</td>
      <td>0.195719</td>
      <td>-0.013349</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SPY</td>
      <td>2014-01-31</td>
      <td>2014-02-07</td>
      <td>0.235160</td>
      <td>0.008383</td>
      <td>0.182371</td>
      <td>-0.041966</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Next, let’s plot the weekly returns (<code>ret</code>) against the implied-vol changes (<code>iv_change</code>) using <code>pandas</code> built-in plotting functionality.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df_spy.plot.scatter(<span class="st">'ret'</span>, <span class="st">'iv_change'</span>, c<span class="op">=</span><span class="st">'k'</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="linear_regression_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Clearly there is a negative relationship, which is what we would expect.</p>
</section>
<section id="regression-example-1-returns-vs-change-in-implied-volatility" class="level3">
<h3 class="anchored" data-anchor-id="regression-example-1-returns-vs-change-in-implied-volatility">Regression Example 1: Returns vs Change in Implied Volatility</h3>
<p>In an exploratory data analysis situation, the visualization above may be all we would need to establish the existance of the leverage effect in SPY. On the other hand, we may want to make this analysis more precise by fitting a <em>linear regression</em> line to the data. A linear regression is a simple model that purports that <code>iv_change</code> is a linear function of the <code>ret</code>. Intuitively, when fitting a linear regression we are trying to find the straight line that has the minimium aggregate distance from all the points in our data.</p>
<p>In the language of statistics, the <code>ret</code> is the <em>independent</em> variable and the <code>iv_change</code> is the <em>dependent</em> variable. The field of machine learning uses different terminology: <code>ret</code> is called the <em>feature</em> and <code>iv_change</code> is called the <em>label</em>. In a generic machine learning problem, we seek to predict a <em>label</em> from one or more <em>features</em>.</p>
<p>We will use <code>sklearn</code> to fit a linear regression to our data. The first step in any learning task with <code>sklearn</code> is to instantiate the model object with a constructor function. In our case, the constructor function is <code>LinearRegression()</code>. We’ll call our model variable <code>iv_model</code>.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>iv_model <span class="op">=</span> LinearRegression(fit_intercept<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>By setting <code>fit_intercept=False</code> we are forcing the line to go through the origin. This seems reasonable from a visual inspection of the data.</p>
<p>Next, we’ll separate out the data that will be used to fit the model.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df_ret <span class="op">=</span> df_spy[[<span class="st">'ret'</span>]][<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>] <span class="co"># features</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df_iv <span class="op">=</span> df_spy[[<span class="st">'iv_change'</span>]][<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>] <span class="co"># labels</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We are now ready to fit the model by using the <code>.fit()</code> method of <code>iv_model</code>.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>iv_model.fit(df_ret, df_iv)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>LinearRegression(fit_intercept=False)</code></pre>
</div>
</div>
<p>Next, let’s check the intercept and coefficient of the line that was fit to our data.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(iv_model.coef_)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(iv_model.intercept_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[-2.17471827]]
0.0</code></pre>
</div>
</div>
<p>This means that our linear regression model has deterimined that the best fitting line is of the form:</p>
<p><span class="math display">\[\begin{align*}
\text{iv-change} = -2.1747 \cdot \text{weekly-return}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
R^2
\end{align*}\]</span></p>
<p>This can be interpreted to mean that every 1% of positive weekly price return leads to a drop in implied volatility of about 2.175%.</p>
<p>In <code>sklearn</code> we can use the <code>.predict()</code> method of our fitted model <code>iv_model</code> to predict labels for a given set of features. In our example, we can predict implied volatility changes for a given set of weekly returns.</p>
<p>Let’s try this for -5%, 0%, and 1%.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>test_values <span class="op">=</span> np.array([<span class="op">-</span><span class="fl">0.05</span>, <span class="dv">0</span>, <span class="fl">0.01</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>iv_model.predict(test_values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([[ 0.10873591],
       [ 0.        ],
       [-0.02174718]])</code></pre>
</div>
</div>
<p>We can also use the <code>.predict()</code> method to graph our fitted line along with our data. This is a bit of a hack, but it works great.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>xfit <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">0.08</span>, <span class="fl">0.055</span>, <span class="dv">100</span>)         <span class="co"># range of line</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>yfit <span class="op">=</span> iv_model.predict(xfit[:, np.newaxis])  <span class="co"># model values in range</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>df_spy.plot.scatter(<span class="st">'ret'</span>, <span class="st">'iv_change'</span>, c<span class="op">=</span><span class="st">'k'</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))<span class="op">;</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.plot(xfit, yfit)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="linear_regression_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In <code>sklearn</code>, all learning models have a <code>.score()</code> method which calculates some kind of measure of accuracy or fit. For a <code>LinearRegression</code> model, <code>.score()</code> gives the <span class="math inline">\(R^2\)</span>.</p>
<p>The <span class="math inline">\(R^{2}\)</span> measures gives a sense for the goodness of fit of a linear regression. It can be interpreted as the percent of variance in the label that is explained by the features.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>iv_model.score(df_ret, df_iv)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>0.5900683519289267</code></pre>
</div>
</div>
<p>Our linear regression explains 59% of the variance in weekly implied volatility changes, from weekly returns.</p>
<p>There is no universal notion of what is a good or bad <span class="math inline">\(R^2\)</span>. That type of value judgement is context specific. Based on my experience of looking at financial data, this scatter plot looks pretty good, meaning that the relationship is strong.</p>
</section>
<section id="regression-example-2-realized-volatility-clustering" class="level3">
<h3 class="anchored" data-anchor-id="regression-example-2-realized-volatility-clustering">Regression Example 2: Realized Volatility Clustering</h3>
<p>A stylized fact about financial asset returns is that realized volatility exhibits clustering. This means that high volatility tends to be followed by high volatility, and low volatility tends to be followed by low volatility.</p>
<p>Let’s try to observe realized voaltility clustering in our weekly SPY data, and then analyze it with linear regression. In particular, let’s observe the relationship between current-week realized volaltility and subsequent-week realized volatility.</p>
<p>We’ll begin by first creating new columns in <code>df_spy</code> to hold this data. Notice that <code>real_vol_0</code> is just a copy of <code>realized_vol</code>.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>df_spy[<span class="st">'real_vol_0'</span>] <span class="op">=</span> df_spy[<span class="st">'realized_vol'</span>]</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>df_spy[<span class="st">'real_vol_1'</span>] <span class="op">=</span> df_spy[<span class="st">'realized_vol'</span>].shift(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>df_spy.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>underlying</th>
      <th>start_date</th>
      <th>end_date</th>
      <th>realized_vol</th>
      <th>ret</th>
      <th>start_iv</th>
      <th>iv_change</th>
      <th>real_vol_0</th>
      <th>real_vol_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SPY</td>
      <td>2014-01-03</td>
      <td>2014-01-10</td>
      <td>0.052949</td>
      <td>0.006812</td>
      <td>0.104300</td>
      <td>-0.010352</td>
      <td>0.052949</td>
      <td>0.147207</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SPY</td>
      <td>2014-01-10</td>
      <td>2014-01-17</td>
      <td>0.147207</td>
      <td>-0.002719</td>
      <td>0.093948</td>
      <td>0.009187</td>
      <td>0.147207</td>
      <td>0.176336</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SPY</td>
      <td>2014-01-17</td>
      <td>2014-01-24</td>
      <td>0.176336</td>
      <td>-0.026206</td>
      <td>0.103134</td>
      <td>0.092585</td>
      <td>0.176336</td>
      <td>0.136391</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SPY</td>
      <td>2014-01-24</td>
      <td>2014-01-31</td>
      <td>0.136391</td>
      <td>-0.003977</td>
      <td>0.195719</td>
      <td>-0.013349</td>
      <td>0.136391</td>
      <td>0.235160</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SPY</td>
      <td>2014-01-31</td>
      <td>2014-02-07</td>
      <td>0.235160</td>
      <td>0.008383</td>
      <td>0.182371</td>
      <td>-0.041966</td>
      <td>0.235160</td>
      <td>0.063975</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Next, let’s take a look at a scatter plot of <code>real_vol_0</code> vs <code>real_vol_1</code>.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df_spy.plot.scatter(<span class="st">'real_vol_0'</span>, <span class="st">'real_vol_1'</span>, c<span class="op">=</span><span class="st">'k'</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="linear_regression_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>At first glance, I would say this scatter plot looks good. The relationship is clearly positive (although quite noisy), as we would expect from the stylized fact of volatility clustering.</p>
<p>However, the data in data in it’s current form is not particularly well suited for linear regression. First of all, the volatilies are bunched near zero, with a few extremely large observations. Additionally, standard deviations are by definition always greater than zero.</p>
<p>For both of these reasons, let’s take the logs of both variables to make the relationship more clear. We’ll do so by simply repopulating the columns in <code>df_spy</code> with the logged values that we want.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>df_spy[<span class="st">'real_vol_0'</span>] <span class="op">=</span> np.log(df_spy[<span class="st">'realized_vol'</span>])</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>df_spy[<span class="st">'real_vol_1'</span>] <span class="op">=</span> np.log(df_spy[<span class="st">'realized_vol'</span>]).shift(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>df_spy.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>underlying</th>
      <th>start_date</th>
      <th>end_date</th>
      <th>realized_vol</th>
      <th>ret</th>
      <th>start_iv</th>
      <th>iv_change</th>
      <th>real_vol_0</th>
      <th>real_vol_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SPY</td>
      <td>2014-01-03</td>
      <td>2014-01-10</td>
      <td>0.052949</td>
      <td>0.006812</td>
      <td>0.104300</td>
      <td>-0.010352</td>
      <td>-2.938431</td>
      <td>-1.915913</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SPY</td>
      <td>2014-01-10</td>
      <td>2014-01-17</td>
      <td>0.147207</td>
      <td>-0.002719</td>
      <td>0.093948</td>
      <td>0.009187</td>
      <td>-1.915913</td>
      <td>-1.735366</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SPY</td>
      <td>2014-01-17</td>
      <td>2014-01-24</td>
      <td>0.176336</td>
      <td>-0.026206</td>
      <td>0.103134</td>
      <td>0.092585</td>
      <td>-1.735366</td>
      <td>-1.992228</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SPY</td>
      <td>2014-01-24</td>
      <td>2014-01-31</td>
      <td>0.136391</td>
      <td>-0.003977</td>
      <td>0.195719</td>
      <td>-0.013349</td>
      <td>-1.992228</td>
      <td>-1.447491</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SPY</td>
      <td>2014-01-31</td>
      <td>2014-02-07</td>
      <td>0.235160</td>
      <td>0.008383</td>
      <td>0.182371</td>
      <td>-0.041966</td>
      <td>-1.447491</td>
      <td>-2.749269</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Let’s replot the log data:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>df_spy.plot.scatter(<span class="st">'real_vol_0'</span>, <span class="st">'real_vol_1'</span>, c<span class="op">=</span><span class="st">'k'</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="linear_regression_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The positive relationship looks more linear after taking logs of both the features and the labels.</p>
<p>As in the previous section, let’s fit a simple linear regression to this data by executing the following steps:</p>
<ol type="1">
<li><p>Instantiate a model with the <code>LinearRegression()</code> constructor.</p></li>
<li><p>Isolate the data for fitting.</p></li>
<li><p>Fit the model with <code>.fit()</code>.</p></li>
<li><p>Check for goodness of fit with <code>.score()</code>.</p></li>
</ol>
<p>First, let’s instantiate our model with the <code>LinearRegression()</code> constructor function. We will call our model <code>rv_model</code>.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>rv_model <span class="op">=</span> LinearRegression(fit_intercept<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, let’s isolate the data that we will use to fit the model.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>df_rv_0 <span class="op">=</span> df_spy[[<span class="st">'real_vol_0'</span>]][:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df_rv_1 <span class="op">=</span> df_spy[[<span class="st">'real_vol_1'</span>]][:<span class="op">-</span><span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now fit the model to the data using the <code>.fit()</code> method of <code>rv_model</code>.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>rv_model.fit(df_rv_0, df_rv_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>LinearRegression()</code></pre>
</div>
</div>
<p>Lastly, we can check the goodness of fit by first visually inspecting the data, and then also by calculating the <span class="math inline">\(R^2\)</span>.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>xfit <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">4.5</span>, <span class="op">-</span><span class="fl">0.75</span>, <span class="dv">100</span>)          <span class="co"># range of line</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>yfit <span class="op">=</span> rv_model.predict(xfit[:, np.newaxis])  <span class="co"># model values in range</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>df_spy.plot.scatter(<span class="st">'real_vol_0'</span>, <span class="st">'real_vol_1'</span>, c<span class="op">=</span><span class="st">'k'</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))<span class="op">;</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>plt.plot(xfit, yfit)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="linear_regression_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>As we can see from the output code below, our <span class="math inline">\(R^2\)</span> is lower for this regression, than the previous one (<code>ret</code> vs <code>iv_change</code>). This is rather obvious from visual inspection of the two graphs - notice how much more spread out the data points are in this graph, versus the graph in the previous analysis.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>rv_model.score(df_rv_0, df_rv_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>0.21785126272072297</code></pre>
</div>
</div>
</section>
<section id="forecasting-realized-volatility" class="level3">
<h3 class="anchored" data-anchor-id="forecasting-realized-volatility">Forecasting Realized Volatility</h3>
<p>Thus far, our regression analysis involved using the entirety of the five years of SPY data that we have avaialable. This is typical if you are using regression for exploratory data analysis, or simply to confirm some kind of directional relationship between two variables.</p>
<p>However, machine learning has aspirations beyond mere exploration - the ultimate goal is usually prediction or forecasting. If you’re serious about that objective, it’s appropriate to split your data into a <em>training</em> set and a <em>testing</em> set. These separate sets are used for two distinct purposes in a two-stage approach:</p>
<ol type="1">
<li><p>Traing data - used to train/fit/learn the model. This phase is referred to as the <em>learning</em> or <em>training</em> phase.</p></li>
<li><p>Testing data - fed into the trained model to produce predictions; we then analyze the predicted values vs true values in the test set, to determine the accuracy of the model. This phase referred to as the <em>testing</em> or <em>generalization</em> phase.</p></li>
</ol>
<p>Let’s try using this two-stage approach with our realized volatility data.</p>
<p>Specifically, rather than fitting a linear regression to the entirety of our data set, let’s instead fit it to only the first four years of the data (2014-2017). We’ll then use the fitted/trained model to forecast realized volatility in 2018.</p>
<p>Let’s begin by instantiating a new <code>LinearRegression</code> object and call it <code>fcst_model</code>.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>fcst_model <span class="op">=</span> LinearRegression(fit_intercept<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, let’s grab the training data from 2014-2018.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>df_rv_0_train <span class="op">=</span> df_spy[[<span class="st">'real_vol_0'</span>]][<span class="dv">0</span>:<span class="dv">208</span>] <span class="co"># this weeks volatility (feature)</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>df_rv_1_train <span class="op">=</span> df_spy[[<span class="st">'real_vol_1'</span>]][<span class="dv">0</span>:<span class="dv">208</span>] <span class="co"># next weeks volatility (label)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We next fit our model to the training data using <code>fcst_model.fit()</code>.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>fcst_model.fit(df_rv_0_train, df_rv_1_train) <span class="co"># fitting the model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>LinearRegression()</code></pre>
</div>
</div>
<p>Let’s print the coefficient, the intercept, and the <span class="math inline">\(R^{2}\)</span> from the model.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Coefficent:      "</span>, np.<span class="bu">round</span>(fcst_model.coef_[<span class="dv">0</span>, <span class="dv">0</span>], <span class="dv">2</span>))    <span class="co"># coefficient</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Intercept:      "</span>, np.<span class="bu">round</span>(fcst_model.intercept_[<span class="dv">0</span>], <span class="dv">2</span>))  <span class="co"># intercept</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"R^2 (training):  "</span>, np.<span class="bu">round</span>(fcst_model.score(df_rv_0_train, df_rv_1_train), <span class="dv">2</span>)) <span class="co"># R^2 from training</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficent:       0.46
Intercept:       -1.34
R^2 (training):   0.21</code></pre>
</div>
</div>
<p>So our linear model is:</p>
<p><span class="math display">\[\log(\text{next-week-realized-vol}) = 0.46 * \log(\text{this-week-realized-vol}) - 1.34.\]</span></p>
<p>It accounts for about 21% of the variability of the weekly <span class="math inline">\(\log(\text{realized-vol})\)</span> in the training set.</p>
<p>Let’s now apply our trained model to data from 2018. We begin be separating out the 2018 <em>testing</em> data into it’s own <code>DataFrame</code>.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>df_rv_0_test <span class="op">=</span> df_spy[[<span class="st">'real_vol_0'</span>]][<span class="dv">209</span>:<span class="op">-</span><span class="dv">1</span>] <span class="co"># features</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>df_rv_1_test <span class="op">=</span> df_spy[[<span class="st">'real_vol_1'</span>]][<span class="dv">209</span>:<span class="op">-</span><span class="dv">1</span>] <span class="co"># labels</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can test how our model predictions compare to the real data by plugging our testing data into the <code>score()</code> method of the model.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>fcst_model.score(df_rv_0_test, df_rv_1_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>0.1484251353811017</code></pre>
</div>
</div>
<p>Alternatively, we can first calculate the predictions, and then calculate the <span class="math inline">\(R^2\)</span> directly on the predicted values. In order to do this we would use the <code>.predict()</code> method of the LinearRegression object along the <code>r2_score()</code> function in the <code>sklearn.metrics</code> module.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>sklearn.metrics.r2_score(df_rv_1_test, fcst_model.predict(df_rv_0_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>0.1484251353811017</code></pre>
</div>
</div>
<p>Notice that the model is more accurate (i.e.&nbsp;has a higher <span class="math inline">\(R^2\)</span>) on the training set than on the testing set - this is always the case.</p>
</section>
<section id="updating-our-forecasting-model-daily" class="level3">
<h3 class="anchored" data-anchor-id="updating-our-forecasting-model-daily">Updating our Forecasting Model Daily</h3>
<p>In our forcasting exercise above, our <code>LinearRegression</code> model was trained on data from 2014-2017, and all of our 2018 forecasts were based on that model. This is probably not what we would do in practice. Instead, we would fit a new model on a regular basis.</p>
<p>In the following code, the training period is updated every week to the most recent four years. We would hope to see slightly improved performance over just training the model once. (The code below is also indcative of patterns used when conducting a backtest.)</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>ix_start <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>ix_end <span class="op">=</span> <span class="dv">208</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>forecasts <span class="op">=</span> np.zeros(<span class="dv">50</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>fcst_model_2 <span class="op">=</span> LinearRegression(fit_intercept<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ix_end <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">208</span>, <span class="dv">258</span>, <span class="dv">1</span>):</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setting training period start date   </span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    ix_start <span class="op">=</span> ix_end <span class="op">-</span> <span class="dv">208</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># selecting training data</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    df_rv_0_train <span class="op">=</span> df_spy[[<span class="st">'real_vol_0'</span>]][ix_start:ix_end]</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    df_rv_1_train <span class="op">=</span> df_spy[[<span class="st">'real_vol_1'</span>]][ix_start:ix_end]</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fitting the model</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>    fcst_model_2.fit(df_rv_0_train, df_rv_1_train)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># forecasting with the newly fitted model</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>    real_vol <span class="op">=</span> df_spy[<span class="st">'real_vol_0'</span>].values[ix_end]</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    fcst_rv <span class="op">=</span> fcst_model_2.coef_[<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">*</span> real_vol  <span class="op">+</span> fcst_model_2.intercept_[<span class="dv">0</span>]</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># saving the current forecast</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>    forecasts[ix_start] <span class="op">=</span> fcst_rv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As we can see, there is a slight improvement when updating the model daily - an <span class="math inline">\(R^2\)</span> of 0.1817 vs 0.1484. I would not expect the improvement to be that significant given the simplistic nature of our forecasting mechanism.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>sklearn.metrics.r2_score(df_spy[[<span class="st">'real_vol_1'</span>]][<span class="dv">208</span>:<span class="dv">258</span>], forecasts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>0.18178835397754134</code></pre>
</div>
</div>
</section>
<section id="further-reading" class="level3">
<h3 class="anchored" data-anchor-id="further-reading">Further Reading</h3>
<p><em>PDSH</em> 5.1 - What Is Machine Learning?</p>
<p><em>PDSH</em> 5.2 - Introducing Scikit-Learn</p>
<p><em>PDSH</em> 5.3 - Hyperparameters and Model Validation</p>
<p><em>PDSH</em> 5.4 - Feature Engineering</p>
<p><em>PDSH</em> 5.6 - In Depth: Linear Regression</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>